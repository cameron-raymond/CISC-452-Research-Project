{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Multi_LSTM.ipynb","provenance":[{"file_id":"1ssWgJmGX7S8KjU_i8yI2v9I0sQCxiQf9","timestamp":1574562077508}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Cb0YhcKv4rox","colab_type":"code","outputId":"e9ffcb2e-bba7-44ab-f4f4-0ea492162af0","executionInfo":{"status":"ok","timestamp":1574783160140,"user_tz":300,"elapsed":39077,"user":{"displayName":"Gabby Bermudez","photoUrl":"","userId":"11892519826564282368"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fx1ZHLzW5t-S","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"AdULhsaToPi5","colab_type":"code","outputId":"683f9000-c70c-4ef5-e82d-e66bd18c503a","executionInfo":{"status":"ok","timestamp":1574615090629,"user_tz":300,"elapsed":1982,"user":{"displayName":"Gabby Bermudez","photoUrl":"","userId":"11892519826564282368"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!ls /content/gdrive/My\\ Drive/School/CISC_452/Project"],"execution_count":0,"outputs":[{"output_type":"stream","text":["data  glove  LSTM.py  preprocessing  README.md\trequirements.txt  saved_models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bTwV7di7_UEH","colab_type":"code","outputId":"22666abe-a09b-4d86-9f0f-a4b92c8f4907","executionInfo":{"status":"ok","timestamp":1574563131210,"user_tz":300,"elapsed":41982,"user":{"displayName":"Gabby Bermudez","photoUrl":"","userId":"11892519826564282368"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["pip install -r /content/gdrive/My\\ Drive/School/CISC_452/Project/requirements.txt\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: absl-py==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 1)) (0.8.1)\n","Requirement already satisfied: astor==0.8.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 2)) (0.8.0)\n","Requirement already satisfied: cachetools==3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 3)) (3.1.1)\n","Requirement already satisfied: certifi==2019.9.11 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 4)) (2019.9.11)\n","Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 5)) (3.0.4)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 6)) (0.2.2)\n","Collecting google-auth==1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl (74kB)\n","\r\u001b[K     |████▍                           | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 20kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 30kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.8MB/s \n","\u001b[?25hRequirement already satisfied: google-auth-oauthlib==0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 8)) (0.4.1)\n","Requirement already satisfied: google-pasta==0.1.8 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 9)) (0.1.8)\n","Collecting grpcio==1.25.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/28/280658104af767431cf25e397157c4f4a8724a446f9dd5a34dac9812e9c9/grpcio-1.25.0-cp36-cp36m-manylinux2010_x86_64.whl (2.4MB)\n","\u001b[K     |████████████████████████████████| 2.4MB 25.9MB/s \n","\u001b[?25hCollecting h5py==2.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 61.7MB/s \n","\u001b[?25hRequirement already satisfied: idna==2.8 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 12)) (2.8)\n","Requirement already satisfied: kaggle==1.5.6 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 13)) (1.5.6)\n","Requirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 14)) (1.0.8)\n","Requirement already satisfied: Keras-Preprocessing==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 15)) (1.1.0)\n","Requirement already satisfied: Markdown==3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 16)) (3.1.1)\n","Collecting nltk==3.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 40.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy==1.17.4 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 18)) (1.17.4)\n","Requirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 19)) (3.1.0)\n","Requirement already satisfied: opt-einsum==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 21)) (0.25.3)\n","Requirement already satisfied: protobuf==3.10.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 22)) (3.10.0)\n","Collecting pyasn1==0.4.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.2MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1-modules==0.2.7 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 24)) (0.2.7)\n","Collecting python-dateutil==2.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n","\u001b[K     |████████████████████████████████| 235kB 67.4MB/s \n","\u001b[?25hRequirement already satisfied: python-slugify==4.0.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 26)) (4.0.0)\n","Collecting pytz==2019.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n","\u001b[K     |████████████████████████████████| 512kB 64.6MB/s \n","\u001b[?25hCollecting requests==2.22.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 10.6MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 29)) (1.3.0)\n","Requirement already satisfied: rsa==4.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 30)) (4.0)\n","Collecting six==1.13.0\n","  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n","Collecting tensorboard==2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 57.3MB/s \n","\u001b[?25hCollecting tensorflow==2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n","\u001b[K     |████████████████████████████████| 86.3MB 133kB/s \n","\u001b[?25hCollecting tensorflow-estimator==2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 63.0MB/s \n","\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 35)) (1.1.0)\n","Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 36)) (1.3)\n","Collecting tqdm==4.38.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/08/8505f192efc72bfafec79655e1d8351d219e2b80b0dec4ae71f50934c17a/tqdm-4.38.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n","\u001b[?25hRequirement already satisfied: urllib3==1.24.3 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 38)) (1.24.3)\n","Requirement already satisfied: Werkzeug==0.16.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 39)) (0.16.0)\n","Requirement already satisfied: wrapt==1.11.2 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 40)) (1.11.2)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth==1.7.1->-r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 7)) (41.6.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.0.1->-r /content/gdrive/My Drive/School/CISC_452/Project/requirements.txt (line 32)) (0.33.6)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449909 sha256=d167436b716d741ce883bb6d59a77fbc1dffdc9224556dca591829db977584f2\n","  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n","Successfully built nltk\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.13.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: botocore 1.13.18 has requirement python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\", but you'll have python-dateutil 2.8.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: six, google-auth, grpcio, h5py, nltk, pyasn1, python-dateutil, pytz, requests, tensorboard, tensorflow-estimator, tensorflow, tqdm\n","  Found existing installation: six 1.12.0\n","    Uninstalling six-1.12.0:\n","      Successfully uninstalled six-1.12.0\n","  Found existing installation: google-auth 1.4.2\n","    Uninstalling google-auth-1.4.2:\n","      Successfully uninstalled google-auth-1.4.2\n","  Found existing installation: grpcio 1.15.0\n","    Uninstalling grpcio-1.15.0:\n","      Successfully uninstalled grpcio-1.15.0\n","  Found existing installation: h5py 2.8.0\n","    Uninstalling h5py-2.8.0:\n","      Successfully uninstalled h5py-2.8.0\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: pyasn1 0.4.7\n","    Uninstalling pyasn1-0.4.7:\n","      Successfully uninstalled pyasn1-0.4.7\n","  Found existing installation: python-dateutil 2.6.1\n","    Uninstalling python-dateutil-2.6.1:\n","      Successfully uninstalled python-dateutil-2.6.1\n","  Found existing installation: pytz 2018.9\n","    Uninstalling pytz-2018.9:\n","      Successfully uninstalled pytz-2018.9\n","  Found existing installation: requests 2.21.0\n","    Uninstalling requests-2.21.0:\n","      Successfully uninstalled requests-2.21.0\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","  Found existing installation: tqdm 4.28.1\n","    Uninstalling tqdm-4.28.1:\n","      Successfully uninstalled tqdm-4.28.1\n","Successfully installed google-auth-1.7.1 grpcio-1.25.0 h5py-2.10.0 nltk-3.4.5 pyasn1-0.4.8 python-dateutil-2.8.1 pytz-2019.3 requests-2.22.0 six-1.13.0 tensorboard-2.0.1 tensorflow-2.0.0 tensorflow-estimator-2.0.1 tqdm-4.38.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dateutil","google","grpc","pyasn1","pytz","requests","six","tqdm"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"VI5hYknp-7JQ","colab_type":"code","outputId":"164876c2-6e39-4a49-8e62-a95204f0d26b","executionInfo":{"status":"ok","timestamp":1574783214308,"user_tz":300,"elapsed":47683,"user":{"displayName":"Gabby Bermudez","photoUrl":"","userId":"11892519826564282368"}},"colab":{"base_uri":"https://localhost:8080/","height":565}},"source":["pip install tensorflow-gpu==2.0.0rc0"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.0.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/12/8c64cc62149cc21c70c55018502831bbf4d42bd62bed196df7de6830d21b/tensorflow_gpu-2.0.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n","\u001b[K     |████████████████████████████████| 380.5MB 43kB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.15.0)\n","Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n","\u001b[K     |████████████████████████████████| 4.3MB 45.1MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.0.8)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.33.6)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.2.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.17.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (1.11.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (3.10.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.8.1)\n","Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n","\u001b[K     |████████████████████████████████| 501kB 46.1MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.1.8)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc0) (0.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0rc0) (0.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0rc0) (3.1.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0rc0) (41.6.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0rc0) (2.8.0)\n","Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n","Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc0 tf-estimator-nightly-1.14.0.dev2019080601\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YC6YfoF1ABDQ","colab_type":"code","outputId":"f3919bb2-27fd-45bd-cfe3-da3575b4a615","executionInfo":{"status":"error","timestamp":1574783114397,"user_tz":300,"elapsed":885,"user":{"displayName":"Gabby Bermudez","photoUrl":"","userId":"11892519826564282368"}},"colab":{"base_uri":"https://localhost:8080/","height":244}},"source":["import sys\n","import os\n","sys.path.append('/content/gdrive/My Drive/School/CISC_452/Project')\n","os.chdir('/content/gdrive/My Drive/School/CISC_452/Project')\n","import numpy                    as np\n","import preprocessing.preprocessing_helpers as preproc\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import Dense, LSTM, Flatten, Embedding, SpatialDropout1D, GlobalMaxPool1D, Bidirectional, Dropout\n","from tensorflow.keras.models import load_model\n","import tensorflow as tf\n","import pandas as pd\n","\n","# VOCAB_SIZE = 5000\n","\n","class Toxic_Comment_LSTM(object):\n","    def __init__(self,x_train=None,y_train=None,x_test=None,y_test=None,embedding_matrix=None,max_length=None,saved_model=None):\n","        super().__init__()\n","        self.max_length     = max_length\n","        self.model          = self.define_model(embedding_matrix,saved_model=saved_model)\n","        self.x_train        = x_train\n","        self.y_train        = y_train\n","        self.x_test         = x_test\n","        self.y_test         = y_test\n","    # #  REGULAR JMODEL\n","    # def define_model(self,embedding_matrix,saved_model=None):\n","    #     if saved_model is None:\n","    #         print(\"--- Initializing Model ---\")\n","    #         VOCAB_SIZE = embedding_matrix.shape[0]\n","    #         model = Sequential()\n","    #         embedding_layer = Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)\n","    #         model.add(embedding_layer)\n","    #         model.add(SpatialDropout1D(0.2))\n","    #         model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2))\n","    #         model.add(Dense(6, activation='sigmoid'))\n","    #         model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    #         return model\n","    #     print(\"--- Loading Model from {} ---\".format(saved_model))\n","    #     model = preproc.load_h5_model(saved_model)\n","    #     if model is None: # If the filepath is wrong or the model hasn't actually been defined earlier\n","    #         print(\"--- no model found, initializing from scrach ---\")\n","    #         return self.define_model(embedding_matrix,saved_model=None)\n","    #     return model\n","\n","    # Multi LSTM\n","    def define_model(self,embedding_matrix,saved_model=None):\n","        if saved_model is None:\n","            print(\"--- Initializing Model ---\")\n","            VOCAB_SIZE = embedding_matrix.shape[0]\n","            model = Sequential()\n","            embedding_layer = Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)\n","            model.add(embedding_layer)\n","            model.add(SpatialDropout1D(0.2))\n","            model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n","            model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2))\n","            model.add(Dense(6, activation='sigmoid'))\n","            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","            return model\n","        print(\"--- Loading Model from {} ---\".format(saved_model))\n","        model = preproc.load_h5_model(saved_model)\n","        if model is None: # If the filepath is wrong or the model hasn't actually been defined earlier\n","            print(\"--- no model found, initializing from scrach ---\")\n","            return self.define_model(embedding_matrix,saved_model=None)\n","        return model\n","  \n","    def train(self,x_train=None,y_train=None):\n","        x_train = self.x_train if x_train is None else x_train\n","        y_train = self.y_train if y_train is None else y_train\n","        epochs = 2\n","        batch_size = 64\n","        # callback = EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001,verbose=1)\n","        history = self.model.fit(x_train,y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,verbose=1)\n","\n","    def validate(self):\n","        # Evaluate the model on the test data using `evaluate`\n","        print('\\n# Evaluate on test data')\n","        print(self.x_test.shape,self.y_test.shape)\n","        results = self.model.evaluate(self.x_test, self.y_test, batch_size=128,verbose=0)\n","        print('test loss, test acc:', results)\n","\n","        # Generate predictions (probabilities -- the output of the last layer)\n","        # on new data using `predict`\n","        shuffle_idx = np.random.choice(np.arange(self.x_test.shape[0]), 10, replace=False)\n","        x_sample, y_sample = self.x_test[shuffle_idx],self.y_test[shuffle_idx]\n","        print('\\n# Generate predictions for {} samples'.format(x_sample.shape[0]))\n","        predictions = self.model.predict(x_sample)\n","        for i,(prediction,target) in enumerate(zip(predictions,y_sample)):\n","            chosen = np.argmax(prediction)\n","            actual = np.argmax(target)\n","            print(\"\\t* prediction {} -> {}, actual -> {}\".format(i,chosen,actual))\n","            print(\"\\t\\t* {}\".format(actual))\n","        print('predictions shape:', predictions.shape)\n","\n","    def save_model(self,file_path=\"saved_models/toxic_comment_LSTM.h5\"):\n","        \n","        preproc.save_h5_model(file_path,self.model)\n","        print(\"--- model saved to {} ---\".format(file_path))\n","\n","if __name__ == \"__main__\":\n","    labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n","\n","    # print('--- Reading test data ---')\n","    # test_df, test_max_length = preproc.return_data('./data/cleaned_test_labels.csv')\n","    # test_data = np.array(test_df['cleaned_text'])\n","    # test_labels = np.array(test_df[labels])\n","\n","    text_df, max_length   = preproc.return_data('./data/{}.csv'.format(\"upsampled_downsampled_train\"))\n","    train  = np.array(text_df['cleaned_text'])\n","    t = Tokenizer(filters = '\"#$%&()*+-/:;<=>@[\\]^_`{|}~')\n","    t.fit_on_texts(train)\n","    train = t.texts_to_sequences(train)\n","    train = pad_sequences(train, maxlen=max_length, padding='post')\n","\n","\n","    # # tokenize the test data\n","    # test_data = t.texts_to_sequences(test_data)\n","    # test_data = pad_sequences(test_data, maxlen=test_max_length, padding='post')\n","\n","\n","\n","    embedding_matrix = np.load('./data/embedding_matrix.npy')\n","\n","    mask = np.random.rand(len(train)) < 0.8\n","\n","    x_train, x_test = train[mask], train[~mask] # split data into train test splits\n","    y_train, y_test = np.array(text_df[mask][labels]), np.array(text_df[~mask][labels])\n","    toxic_Comment_LSTM = Toxic_Comment_LSTM(x_test=x_test,y_test=y_test, embedding_matrix=embedding_matrix, saved_model='saved_models/toxic_comment_LSTM_multiLSTM.h5')\n","\n","    # print('--- Predicting ---')\n","    # toxic_Comment_LSTM.model.evaluate(test_data, test_labels)\n","    print(\"--- Training Model ---\")\n","    toxic_Comment_LSTM.model.fit(x_train, y_train)\n","    print(\"--- Saving Model ---\")\n","    toxic_Comment_LSTM.save_model('saved_models/toxic_comment_LSTM_multiLSTM.h5')\n","\n","\n"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-15c6b71c8886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/School/CISC_452/Project'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/School/CISC_452/Project'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m                    \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing_helpers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/School/CISC_452/Project'"]}]}]}